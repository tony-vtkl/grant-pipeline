"""ScoringResult - Output model for REQ-3 (Weighted LLM Scoring Engine)."""

from datetime import datetime
from typing import Optional
from pydantic import BaseModel, Field


class DimensionScore(BaseModel):
    """Individual dimension score with evidence."""
    score: float = Field(..., ge=0, le=100, description="0-100 score")
    evidence_citations: list[str] = Field(..., description="Direct quotes from raw_text")


class ScoringResult(BaseModel):
    """Result of LLM-based opportunity scoring.
    
    Generated by REQ-3, consumed by REQ-4 (reports), REQ-8 (learning loop).
    """
    
    # Reference
    opportunity_id: str = Field(..., description="Links to GrantOpportunity.source_opportunity_id")
    
    # Five weighted dimensions (per INTAKE BLOCK 4)
    mission_fit: DimensionScore = Field(..., description="Mission Fit (25%)")
    eligibility: DimensionScore = Field(..., description="Eligibility (25%)")
    technical_alignment: DimensionScore = Field(..., description="Technical Alignment (20%)")
    financial_viability: DimensionScore = Field(..., description="Financial Viability (15%)")
    strategic_value: DimensionScore = Field(..., description="Strategic Value (15%)")
    
    # Composite
    composite_score: float = Field(..., ge=0, le=100, description="Weighted composite score")
    verdict: str = Field(..., description="GO (80-100), SHAPE (60-79), MONITOR (40-59), NO-GO (0-39)")
    
    # Metadata
    scored_at: datetime = Field(default_factory=datetime.utcnow)
    scoring_weights_version: str = Field(default="1.0", description="Weight version used")
    llm_model: str = Field(..., description="Model used for scoring")
    
    class Config:
        json_schema_extra = {
            "example": {
                "opportunity_id": "HHS-OS-24-001",
                "mission_fit": {
                    "score": 90.0,
                    "evidence_citations": [
                        "seeking AI solutions for healthcare data analysis"
                    ]
                },
                "eligibility": {
                    "score": 0.0,
                    "evidence_citations": [
                        "Requires 8(a) certification"
                    ]
                },
                "technical_alignment": {
                    "score": 85.0,
                    "evidence_citations": [
                        "machine learning, data governance, automation"
                    ]
                },
                "financial_viability": {
                    "score": 80.0,
                    "evidence_citations": [
                        "Award range: $1M-$2.5M"
                    ]
                },
                "strategic_value": {
                    "score": 75.0,
                    "evidence_citations": [
                        "federal healthcare sector alignment"
                    ]
                },
                "composite_score": 39.0,
                "verdict": "NO-GO",
                "scored_at": "2024-02-20T00:00:00Z",
                "scoring_weights_version": "1.0",
                "llm_model": "claude-haiku-4-5"
            }
        }
